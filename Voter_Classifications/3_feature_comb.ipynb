{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, boxcox\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import KFold,GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics, preprocessing\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv('../ProjectFiles/File1.csv')\n",
    "train_label_size = train_label.shape[0]\n",
    "train = pd.read_csv('../ProjectFiles/File2.csv')\n",
    "train_size = train.shape[0]\n",
    "test = pd.read_csv('../ProjectFiles/File3.csv')\n",
    "test_size = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29231, 149)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.concat([test,train], axis=1)\n",
    "df_test = df_test.loc[:,~df_test.columns.duplicated()]\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29231, 150)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.concat([df_test,train_label], axis=1)\n",
    "df_full = df_full.loc[:,~df_full.columns.duplicated()]\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.SPENDINGRESPONSE.replace([\"Spend to Improve Economy\",\"Reduce National Debt and Deficit\"], [1,0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Categorical features: 24\n",
      "Categorical features: ['State', 'f1', 'f3', 'f12', 'f13', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f108', 'f110', 'f114', 'f115', 'f118', 'f119', 'f120', 'f121', 'f122', 'f126']\n",
      "# of Numerical features: 124\n",
      "Numerical features: ['f2', 'f93', 'f94', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f104', 'f105', 'f106', 'f107', 'f109', 'f111', 'f112', 'f113', 'f116', 'f117', 'f123', 'f124', 'f125', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147']\n",
      "ID: ID, target: SPENDINGRESPONSE\n"
     ]
    }
   ],
   "source": [
    "data_types = df_full.dtypes  \n",
    "cat_cols = list(data_types[data_types=='object'].index)\n",
    "con_cols = list(data_types[data_types=='int64'].index) + list(data_types[data_types=='float64'].index)\n",
    "\n",
    "id_col = 'ID'\n",
    "target_col = 'SPENDINGRESPONSE'\n",
    "con_cols.remove('ID')\n",
    "con_cols.remove('SPENDINGRESPONSE')\n",
    "\n",
    "print(\"# of Categorical features:\", len(cat_cols))\n",
    "print(\"Categorical features:\", cat_cols)\n",
    "print(\"# of Numerical features:\", len(con_cols))\n",
    "print(\"Numerical features:\", con_cols)\n",
    "print(\"ID: %s, target: %s\" %( id_col, target_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['State', 'f1', 'f3', 'f108', 'f110', 'f114', 'f115', 'f121', 'f122', 'f126']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_encod_cat = []\n",
    "for i in cat_cols:\n",
    "    if df_full[i].value_counts().size >= 15:\n",
    "        freq_encod_cat.append(i)\n",
    "freq_encod_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [x for x in cat_cols if x not in freq_encod_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining Columns: f12_f13\n",
      "Combining Columns: f12_f95\n",
      "Combining Columns: f12_f96\n",
      "Combining Columns: f12_f97\n",
      "Combining Columns: f12_f98\n",
      "Combining Columns: f12_f99\n",
      "Combining Columns: f12_f100\n",
      "Combining Columns: f12_f101\n",
      "Combining Columns: f12_f102\n",
      "Combining Columns: f12_f103\n",
      "Combining Columns: f12_f118\n",
      "Combining Columns: f12_f119\n",
      "Combining Columns: f12_f120\n",
      "Combining Columns: f13_f95\n",
      "Combining Columns: f13_f96\n",
      "Combining Columns: f13_f97\n",
      "Combining Columns: f13_f98\n",
      "Combining Columns: f13_f99\n",
      "Combining Columns: f13_f100\n",
      "Combining Columns: f13_f101\n",
      "Combining Columns: f13_f102\n",
      "Combining Columns: f13_f103\n",
      "Combining Columns: f13_f118\n",
      "Combining Columns: f13_f119\n",
      "Combining Columns: f13_f120\n",
      "Combining Columns: f95_f96\n",
      "Combining Columns: f95_f97\n",
      "Combining Columns: f95_f98\n",
      "Combining Columns: f95_f99\n",
      "Combining Columns: f95_f100\n",
      "Combining Columns: f95_f101\n",
      "Combining Columns: f95_f102\n",
      "Combining Columns: f95_f103\n",
      "Combining Columns: f95_f118\n",
      "Combining Columns: f95_f119\n",
      "Combining Columns: f95_f120\n",
      "Combining Columns: f96_f97\n",
      "Combining Columns: f96_f98\n",
      "Combining Columns: f96_f99\n",
      "Combining Columns: f96_f100\n",
      "Combining Columns: f96_f101\n",
      "Combining Columns: f96_f102\n",
      "Combining Columns: f96_f103\n",
      "Combining Columns: f96_f118\n",
      "Combining Columns: f96_f119\n",
      "Combining Columns: f96_f120\n",
      "Combining Columns: f97_f98\n",
      "Combining Columns: f97_f99\n",
      "Combining Columns: f97_f100\n",
      "Combining Columns: f97_f101\n",
      "Combining Columns: f97_f102\n",
      "Combining Columns: f97_f103\n",
      "Combining Columns: f97_f118\n",
      "Combining Columns: f97_f119\n",
      "Combining Columns: f97_f120\n",
      "Combining Columns: f98_f99\n",
      "Combining Columns: f98_f100\n",
      "Combining Columns: f98_f101\n",
      "Combining Columns: f98_f102\n",
      "Combining Columns: f98_f103\n",
      "Combining Columns: f98_f118\n",
      "Combining Columns: f98_f119\n",
      "Combining Columns: f98_f120\n",
      "Combining Columns: f99_f100\n",
      "Combining Columns: f99_f101\n",
      "Combining Columns: f99_f102\n",
      "Combining Columns: f99_f103\n",
      "Combining Columns: f99_f118\n",
      "Combining Columns: f99_f119\n",
      "Combining Columns: f99_f120\n",
      "Combining Columns: f100_f101\n",
      "Combining Columns: f100_f102\n",
      "Combining Columns: f100_f103\n",
      "Combining Columns: f100_f118\n",
      "Combining Columns: f100_f119\n",
      "Combining Columns: f100_f120\n",
      "Combining Columns: f101_f102\n",
      "Combining Columns: f101_f103\n",
      "Combining Columns: f101_f118\n",
      "Combining Columns: f101_f119\n",
      "Combining Columns: f101_f120\n",
      "Combining Columns: f102_f103\n",
      "Combining Columns: f102_f118\n",
      "Combining Columns: f102_f119\n",
      "Combining Columns: f102_f120\n",
      "Combining Columns: f103_f118\n",
      "Combining Columns: f103_f119\n",
      "Combining Columns: f103_f120\n",
      "Combining Columns: f118_f119\n",
      "Combining Columns: f118_f120\n",
      "Combining Columns: f119_f120\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for comb in itertools.combinations(cat_cols, 2):\n",
    "    feat = comb[0] + \"_\" + comb[1]\n",
    "    df_full[feat] = df_full[comb[0]] + df_full[comb[1]]\n",
    "    print('Combining Columns:', feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>State</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f102_f103</th>\n",
       "      <th>f102_f118</th>\n",
       "      <th>f102_f119</th>\n",
       "      <th>f102_f120</th>\n",
       "      <th>f103_f118</th>\n",
       "      <th>f103_f119</th>\n",
       "      <th>f103_f120</th>\n",
       "      <th>f118_f119</th>\n",
       "      <th>f118_f120</th>\n",
       "      <th>f119_f120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3094</td>\n",
       "      <td>AK</td>\n",
       "      <td>AK01</td>\n",
       "      <td>69</td>\n",
       "      <td>E</td>\n",
       "      <td>61.0</td>\n",
       "      <td>55.33333</td>\n",
       "      <td>66.0</td>\n",
       "      <td>52.33333</td>\n",
       "      <td>49.25</td>\n",
       "      <td>...</td>\n",
       "      <td>AA</td>\n",
       "      <td>AG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13856</td>\n",
       "      <td>AK</td>\n",
       "      <td>AK01</td>\n",
       "      <td>59</td>\n",
       "      <td>M</td>\n",
       "      <td>61.0</td>\n",
       "      <td>55.33333</td>\n",
       "      <td>66.0</td>\n",
       "      <td>52.33333</td>\n",
       "      <td>49.25</td>\n",
       "      <td>...</td>\n",
       "      <td>BA</td>\n",
       "      <td>BG</td>\n",
       "      <td>BR</td>\n",
       "      <td>BP</td>\n",
       "      <td>AG</td>\n",
       "      <td>AR</td>\n",
       "      <td>AP</td>\n",
       "      <td>GR</td>\n",
       "      <td>GP</td>\n",
       "      <td>RP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16213</td>\n",
       "      <td>AK</td>\n",
       "      <td>AK01</td>\n",
       "      <td>63</td>\n",
       "      <td>D</td>\n",
       "      <td>61.0</td>\n",
       "      <td>55.33333</td>\n",
       "      <td>66.0</td>\n",
       "      <td>52.33333</td>\n",
       "      <td>49.25</td>\n",
       "      <td>...</td>\n",
       "      <td>AJ</td>\n",
       "      <td>AG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AP</td>\n",
       "      <td>JG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17196</td>\n",
       "      <td>AK</td>\n",
       "      <td>AK01</td>\n",
       "      <td>55</td>\n",
       "      <td>D</td>\n",
       "      <td>61.0</td>\n",
       "      <td>55.33333</td>\n",
       "      <td>66.0</td>\n",
       "      <td>52.33333</td>\n",
       "      <td>49.25</td>\n",
       "      <td>...</td>\n",
       "      <td>AJ</td>\n",
       "      <td>AG</td>\n",
       "      <td>AN</td>\n",
       "      <td>AP</td>\n",
       "      <td>JG</td>\n",
       "      <td>JN</td>\n",
       "      <td>JP</td>\n",
       "      <td>GN</td>\n",
       "      <td>GP</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17762</td>\n",
       "      <td>AK</td>\n",
       "      <td>AK01</td>\n",
       "      <td>75</td>\n",
       "      <td>D</td>\n",
       "      <td>61.0</td>\n",
       "      <td>55.33333</td>\n",
       "      <td>66.0</td>\n",
       "      <td>52.33333</td>\n",
       "      <td>49.25</td>\n",
       "      <td>...</td>\n",
       "      <td>AJ</td>\n",
       "      <td>AG</td>\n",
       "      <td>AN</td>\n",
       "      <td>AC</td>\n",
       "      <td>JG</td>\n",
       "      <td>JN</td>\n",
       "      <td>JC</td>\n",
       "      <td>GN</td>\n",
       "      <td>GC</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID State    f1  f2 f3    f4        f5    f6        f7     f8    ...      \\\n",
       "0   3094    AK  AK01  69  E  61.0  55.33333  66.0  52.33333  49.25    ...       \n",
       "1  13856    AK  AK01  59  M  61.0  55.33333  66.0  52.33333  49.25    ...       \n",
       "2  16213    AK  AK01  63  D  61.0  55.33333  66.0  52.33333  49.25    ...       \n",
       "3  17196    AK  AK01  55  D  61.0  55.33333  66.0  52.33333  49.25    ...       \n",
       "4  17762    AK  AK01  75  D  61.0  55.33333  66.0  52.33333  49.25    ...       \n",
       "\n",
       "   f102_f103  f102_f118  f102_f119 f102_f120 f103_f118  f103_f119  f103_f120  \\\n",
       "0         AA         AG        NaN       NaN        AG        NaN        NaN   \n",
       "1         BA         BG         BR        BP        AG         AR         AP   \n",
       "2         AJ         AG        NaN        AP        JG        NaN         JP   \n",
       "3         AJ         AG         AN        AP        JG         JN         JP   \n",
       "4         AJ         AG         AN        AC        JG         JN         JC   \n",
       "\n",
       "   f118_f119  f118_f120  f119_f120  \n",
       "0        NaN        NaN        NaN  \n",
       "1         GR         GP         RP  \n",
       "2        NaN         GP        NaN  \n",
       "3         GN         GP         NP  \n",
       "4         GN         GC         NC  \n",
       "\n",
       "[5 rows x 241 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_2 = df_full.dtypes  \n",
    "cat_cols_2 = list(data_types_2[data_types_2=='object'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['State', 'f1', 'f3', 'f12', 'f13', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f108', 'f110', 'f114', 'f115', 'f118', 'f119', 'f120', 'f121', 'f122', 'f126', 'f12_f13', 'f12_f95', 'f12_f96', 'f12_f97', 'f12_f98', 'f12_f99', 'f12_f100', 'f12_f101', 'f12_f102', 'f12_f103', 'f12_f118', 'f12_f119', 'f12_f120', 'f13_f95', 'f13_f96', 'f13_f97', 'f13_f98', 'f13_f99', 'f13_f100', 'f13_f101', 'f13_f102', 'f13_f103', 'f13_f118', 'f13_f119', 'f13_f120', 'f95_f96', 'f95_f97', 'f95_f98', 'f95_f99', 'f95_f100', 'f95_f101', 'f95_f102', 'f95_f103', 'f95_f118', 'f95_f119', 'f95_f120', 'f96_f97', 'f96_f98', 'f96_f99', 'f96_f100', 'f96_f101', 'f96_f102', 'f96_f103', 'f96_f118', 'f96_f119', 'f96_f120', 'f97_f98', 'f97_f99', 'f97_f100', 'f97_f101', 'f97_f102', 'f97_f103', 'f97_f118', 'f97_f119', 'f97_f120', 'f98_f99', 'f98_f100', 'f98_f101', 'f98_f102', 'f98_f103', 'f98_f118', 'f98_f119', 'f98_f120', 'f99_f100', 'f99_f101', 'f99_f102', 'f99_f103', 'f99_f118', 'f99_f119', 'f99_f120', 'f100_f101', 'f100_f102', 'f100_f103', 'f100_f118', 'f100_f119', 'f100_f120', 'f101_f102', 'f101_f103', 'f101_f118', 'f101_f119', 'f101_f120', 'f102_f103', 'f102_f118', 'f102_f119', 'f102_f120', 'f103_f118', 'f103_f119', 'f103_f120', 'f118_f119', 'f118_f120', 'f119_f120'] 115\n"
     ]
    }
   ],
   "source": [
    "print(cat_cols_2, len(cat_cols_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols_2 = [x for x in cat_cols_2 if x not in freq_encod_cat]\n",
    "cat_cols_2 = [x for x in cat_cols_2 if x not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "print(len(cat_cols_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label enconding finished in 2.045571 seconds\n"
     ]
    }
   ],
   "source": [
    "LBL = preprocessing.LabelEncoder()\n",
    "start = time.time()\n",
    "LE_map = dict()\n",
    "for cat_col in cat_cols_2:\n",
    "    df_full[cat_col] = LBL.fit_transform(df_full[cat_col].astype(str))\n",
    "    LE_map[cat_col]=dict(zip(LBL.classes_, LBL.transform(LBL.classes_)))\n",
    "print ('Label enconding finished in %f seconds' % (time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot-encoding finished in 2.152405 seconds\n",
      "(29231, 3967)\n"
     ]
    }
   ],
   "source": [
    "OHE = preprocessing.OneHotEncoder(sparse=False)\n",
    "start = time.time()\n",
    "OHE.fit(df_full[cat_cols_2])\n",
    "OHE_data = OHE.transform(df_full[cat_cols_2])\n",
    "print ('One-hot-encoding finished in %f seconds' % (time.time()-start))\n",
    "\n",
    "OHE_vars = [var + '_' + str(level).replace(' ','_')\\\n",
    "                for var in cat_cols_2 for level in LE_map[var]]\n",
    "\n",
    "print (OHE_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no obvious relationship among numerical features. And the feature importance from XGBoost shows that numerical features dominant in the model. The feature combination here will just limited to categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat((df_full.ID, pd.DataFrame(OHE_data,columns=OHE_vars)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_csv('../data/input_cat_comb1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
