{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, boxcox\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import KFold,GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics, preprocessing\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = pd.read_csv('../data/input_proc2.csv')\n",
    "df_catcomb = pd.read_csv('../data/input_cat_comb1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9231"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../ProjectFiles/File2.csv')\n",
    "train_size = train.shape[0]\n",
    "df_ori.SPENDINGRESPONSE[train_size:].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29231, 4332)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_ori,df_catcomb], axis=1)\n",
    "df = df.loc[:,~df.columns.duplicated()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID' 'f3_A' 'f3_B' ... 'f119_f120_US' 'f119_f120_UX' 'f119_f120_nan']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.drop('ID', axis=1).values\n",
    "train_x = df[:train_size].drop(['ID','SPENDINGRESPONSE'], axis=1).values\n",
    "train_y = df[:train_size].SPENDINGRESPONSE.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same paramters from previous test to build the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_x, label=train_y, missing = np.NAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.303837+0.00144003\ttest-error:0.3119+0.00203429\n",
      "5 0.3119002 1\n",
      "[0]\ttrain-error:0.301037+0.00216212\ttest-error:0.31215+0.00239473\n",
      "6 0.31215020000000004 2\n",
      "[0]\ttrain-error:0.298712+0.00283042\ttest-error:0.31305+0.00254858\n",
      "7 0.31305020000000006 2\n",
      "[0]\ttrain-error:0.295213+0.00387493\ttest-error:0.316+0.00231814\n",
      "8 0.3160002 2\n",
      "[0]\ttrain-error:0.291388+0.00519291\ttest-error:0.31825+0.00467022\n",
      "9 0.3182501999999999 2\n",
      "[0]\ttrain-error:0.2855+0.00803079\ttest-error:0.32035+0.00534301\n",
      "10 0.32035 2\n",
      "Best max_depth is 5\n",
      "CPU times: user 1h 37min 58s, sys: 1min 36s, total: 1h 39min 34s\n",
      "Wall time: 27min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "for max_depth in [5, 6, 7, 8, 9, 10]:\n",
    "\n",
    "    params = dict()\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    params['eta'] = 0.1\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = 1\n",
    "    params['colsample_bytree'] = 1\n",
    "    params['subsample'] = 1\n",
    "    params['gamma'] = 0\n",
    "    params['seed'] = 1234\n",
    "    #params['eval_metric'] = 'error'\n",
    "    cv_results = xgb.cv(params, dtrain,\n",
    "                    num_boost_round=10000,\n",
    "                    nfold=5,\n",
    "                    maximize=True, \n",
    "                    stratified=True,\n",
    "                    shuffle=True,\n",
    "                    verbose_eval=500,\n",
    "                    seed=1234,\n",
    "                    early_stopping_rounds=50)\n",
    "\n",
    "    best_score = cv_results['test-error-mean'].min()\n",
    "    best_iteration = len(cv_results)           \n",
    "    print(max_depth, best_score, best_iteration)\n",
    "    scores.append([best_score, params['eta'], params['max_depth'], params['min_child_weight'],\n",
    "                   params['colsample_bytree'], params['subsample'], params['gamma'], best_iteration])\n",
    "\n",
    "scores = pd.DataFrame(scores, columns=['score', 'eta', 'max_depth', 'min_child_weight',\n",
    "                                       'colsample_bytree', 'subsample', 'gamma', 'best_iteration'])\n",
    "best_max_depth = scores.sort_values(by='score', ascending=True)['max_depth'].values[0]\n",
    "print('Best max_depth is', best_max_depth)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30845 1\n"
     ]
    }
   ],
   "source": [
    "xgb_params = dict()\n",
    "xgb_params['colsample_bytree'] = 0.5556186387129007\n",
    "xgb_params['gamma'] = 1.9426003754806411\n",
    "xgb_params['max_depth'] = 3\n",
    "xgb_params['min_child_weight'] = 80\n",
    "xgb_params['subsample'] = 0.2678974963534382\n",
    "xgb_params['objective'] = 'binary:logistic'\n",
    "xgb_params['eta'] = 0.01  # Smaller\n",
    "xgb_params['max_depth'] = int(xgb_params['max_depth'])\n",
    "xgb_params['min_child_weight'] = int(xgb_params['min_child_weight'])\n",
    "xgb_params['subsample'] = xgb_params['subsample']\n",
    "xgb_params['colsample_bytree'] = xgb_params['colsample_bytree']\n",
    "xgb_params['gamma'] = xgb_params['gamma']\n",
    "xgb_params['seed'] = 1234\n",
    "\n",
    "cv_results = xgb.cv(params, xgb.DMatrix(train_x, label=train_y.reshape(train_x.shape[0], 1), missing=np.NAN),\n",
    "                    num_boost_round=10000,\n",
    "                    nfold=5,\n",
    "                    maximize=True,\n",
    "                    stratified=True,\n",
    "                    shuffle=True,\n",
    "                    seed=1234,\n",
    "                    early_stopping_rounds=50)\n",
    "\n",
    "best_iteration = len(cv_results)\n",
    "best_score = cv_results['test-error-mean'].min()\n",
    "print(best_score, best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(xgb_params,\n",
    "                  xgb.DMatrix(train_x, label=train_y.reshape(train_x.shape[0], 1), missing=np.NAN),\n",
    "                  num_boost_round=best_iteration\n",
    "                  )\n",
    "\n",
    "df_test = df.drop(['ID','SPENDINGRESPONSE'], axis=1).values\n",
    "preds = model.predict(xgb.DMatrix(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({'ID': df.ID, 'Probability': preds})\n",
    "sub_df.to_csv(\"../data/xgb_catcomb_prob_opt1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29231, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
